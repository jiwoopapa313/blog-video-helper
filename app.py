import os, time, json, uuid, base64
from datetime import datetime, timezone, timedelta

import streamlit as st
from streamlit.components.v1 import html as comp_html
from openai import OpenAI

# =============================
# ê¸°ë³¸ ì„¸íŒ…
# =============================
KST = timezone(timedelta(hours=9))
st.set_page_config(page_title="ë¸”ë¡œê·¸Â·ìœ íŠœë¸Œ í†µí•© ìƒì„±ê¸° (Pro)", page_icon="ğŸ§°", layout="wide")
st.title("ğŸ§° ë¸”ë¡œê·¸Â·ìœ íŠœë¸Œ í†µí•© ìƒì„±ê¸° â€” Pro ë²„ì „")
st.caption(f"KST {datetime.now(KST).strftime('%Y-%m-%d %H:%M')} Â· ê³ í’ˆì§ˆ ìƒì„± + ë³µì‚¬ ë²„íŠ¼ + ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸")

# =============================
# ê³µí†µ: OpenAI í´ë¼ì´ì–¸íŠ¸ & ì•ˆì „ ì¬ì‹œë„
# =============================

def _get_client():
    api_key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY", "")
    if not api_key:
        st.warning("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Secretsì— í‚¤ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
    return OpenAI(api_key=api_key)


def _retry(func, *args, **kwargs):
    backoff = [0.5, 1, 2, 4]
    last_err = None
    for i, wait in enumerate(backoff):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            last_err = e
            if i < len(backoff) - 1:
                time.sleep(wait)
            else:
                raise last_err


def chat_complete(system_prompt: str, user_prompt: str, model: str, temperature: float):
    client = _get_client()
    def _call():
        return client.chat.completions.create(
            model=model,
            temperature=temperature,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
        )
    resp = _retry(_call)
    return resp.choices[0].message.content.strip()

# =============================
# UI ìœ í‹¸: ë³µì‚¬ ê°€ëŠ¥í•œ ë¸”ë¡
# =============================

def copy_block(title: str, text: str, height: int = 160):
    # ê° ë¸”ë¡ë§ˆë‹¤ textarea idë¥¼ ê³ ìœ í•˜ê²Œ ë§Œë“¤ì–´ ì¶©ëŒ ë°©ì§€
    tid = "ta" + str(uuid.uuid4()).replace('-', '')
    esc = (text or "").replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
    comp_html(f"""
    <div style='border:1px solid #e5e7eb;border-radius:10px;padding:10px;margin:8px 0;'>
      <div style='font-weight:600;margin-bottom:6px'>{title}</div>
      <textarea id='{tid}' style='width:100%;height:{height}px;border:1px solid #d1d5db;border-radius:8px;padding:8px;'>{esc}</textarea>
      <button onclick=\"navigator.clipboard.writeText(document.getElementById('{tid}').value)\" style='margin-top:8px;padding:6px 10px;border-radius:8px;border:1px solid #d1d5db;cursor:pointer;'>ğŸ“‹ ë³µì‚¬</button>
    </div>
    """, height=height+110)

# =============================
# ì‚¬ì´ë“œë°” ì„¤ì •
# =============================
with st.sidebar:
    st.header("âš™ï¸ ìƒì„± ì„¤ì •")
    st.info("â€» Streamlit Secretsì— OPENAI_API_KEYë§Œ ë„£ìœ¼ë©´ ë©ë‹ˆë‹¤.", icon="ğŸ”")
    model_text = st.selectbox("í…ìŠ¤íŠ¸ ëª¨ë¸", ["gpt-4o-mini", "gpt-4o"], index=0)
    temperature = st.slider("ì°½ì˜ì„±(temperature)", 0.0, 1.2, 0.6, 0.1)
    polish_toggle = st.checkbox("í’ˆì§ˆ ì—…ìŠ¤ì¼€ì¼(4oë¡œ í›„ê°€ê³µ)", value=False)

# =============================
# ì…ë ¥ ì˜ì—­
# =============================
st.subheader("ğŸ¯ ì£¼ì œ & íƒ€ê¹ƒ")
col1, col2, col3 = st.columns([2, 1, 1])
with col1:
    topic = st.text_input("ì£¼ì œ", value="ì¹˜ë§¤ ì˜ˆë°© ë‘ë‡Œ ê±´ê°•ë²•")
with col2:
    audience = st.selectbox("íƒ€ê¹ƒ", ["50~70ëŒ€ ì‹œë‹ˆì–´", "30~50ëŒ€ ì£¼ë¶€", "ì¼ë°˜ ì„±ì¸"], index=0)
with col3:
    tone = st.selectbox("í†¤/ìŠ¤íƒ€ì¼", ["ì‹œë‹ˆì–´ ì¹œí™”í˜•", "ì „ë¬¸ê°€í˜•", "ì¹œê·¼í•œ ì„¤ëª…í˜•"], index=0)

colA, colB = st.columns(2)

# =============================
# ìœ íŠœë¸Œ ìƒì„±
# =============================
with colA:
    st.markdown("### ğŸ“º ìœ íŠœë¸Œ íŒ¨í‚¤ì§€ â€” ì œëª©â†’ì„¤ëª…â†’ìë§‰â†’ì´ë¯¸ì§€â†’íƒœê·¸")
    if st.button("â–¶ ìœ íŠœë¸Œ ìƒì„±", type="primary"):
        try:
            sys = (
                "You are a seasoned Korean YouTube scriptwriter for seniors. "
                "Always return STRICT JSON only (no prose). Titles must be natural, clickable but not clickbait. "
                "Chapters are Vrew-friendly: 2~4 sentences each. Image prompts must include English prompt and Korean gloss for Korean seniors context."
            )
            user = f"""
[ì£¼ì œ] {topic}
[íƒ€ê¹ƒ] {audience}
[í†¤] {tone}

Return JSON with this schema:
{{
  "titles": ["...", "...", "..."],
  "description": "(3~5ì¤„)",
  "chapters": [
     {{"title":"ì¸íŠ¸ë¡œ","script":"..."}},
     {{"title":"Tip1","script":"..."}},
     {{"title":"Tip2","script":"..."}},
     {{"title":"Tip3","script":"..."}},
     {{"title":"Tip4","script":"..."}},
     {{"title":"Tip5","script":"..."}},
     {{"title":"ì—”ë”©","script":"..."}}
  ],
  "image_prompts": [
     {{"label":"ì¸ë„¤ì¼","en":"...","ko":"..."}},
     {{"label":"ë³¸ë¬¸1","en":"...","ko":"..."}},
     {{"label":"ë³¸ë¬¸2","en":"...","ko":"..."}}
  ],
  "hashtags": ["#..", "#..", "#..", "#..", "#.."]
}}
- Constraints:
  1) Put titles first. 2) Hashtags appear at the end. 3) Focus on practical, trustworthy advice for Korean seniors.
"""
            raw = chat_complete(sys, user, model_text, temperature)
            try:
                data = json.loads(raw)
            except Exception:
                sys2 = sys + " Return ONLY compact JSON without prose."
                raw = chat_complete(sys2, user, model_text, temperature)
                data = json.loads(raw)

            # ì—…ìŠ¤ì¼€ì¼(ì„ íƒ) â€” ì œëª©/ì„¤ëª…/ìë§‰ ë‹¤ë“¬ê¸°
            if polish_toggle:
                polish_in = json.dumps(data, ensure_ascii=False)
                sys_p = "Polish the Korean text for dignity and clarity, keep the same structure, return JSON only."
                polished = chat_complete(sys_p, polish_in, "gpt-4o", 0.4)
                try:
                    data = json.loads(polished)
                except Exception:
                    pass

            # â‘  ì œëª©
            st.markdown("**â‘  ì˜ìƒ ì œëª© 3ê°œ**")
            yt_titles = [f"{i+1}. {t}" for i, t in enumerate(data.get("titles", [])[:3])]
            copy_block("ì˜ìƒ ì œëª© ë³µì‚¬", "\n".join(yt_titles), 110)

            # â‘¡ ì„¤ëª…
            st.markdown("**â‘¡ ì˜ìƒ ì„¤ëª…**")
            copy_block("ì˜ìƒ ì„¤ëª… ë³µì‚¬", data.get("description", ""), 160)

            # â‘¢ ë¸Œë£¨ ìë§‰(ì±•í„°ë³„ + ì „ì²´)
            st.markdown("**â‘¢ ë¸Œë£¨ ìë§‰ (ì±•í„°ë³„ ë³µì‚¬ + ì „ì²´ ë³µì‚¬)**")
            chapters = data.get("chapters", [])
            all_lines = []
            for ch in chapters:
                title = ch.get("title", "ì±•í„°")
                script = ch.get("script", "")
                all_lines.append(script)
                copy_block(f"[{title}] ìë§‰", script, 140)
            copy_block("ë¸Œë£¨ ìë§‰ â€” ì „ì²´ ì¼ê´„ ë³µì‚¬", "\n\n".join(all_lines), 220)

            # â‘£ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸
            st.markdown("**â‘£ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (EN + KO)**")
            for p in data.get("image_prompts", []):
                lbl = p.get("label", "ì´ë¯¸ì§€")
                copy_block(f"[{lbl}] EN", p.get("en", ""), 100)
                copy_block(f"[{lbl}] KO", p.get("ko", ""), 90)

            # â‘¤ í•´ì‹œíƒœê·¸ (ë§ˆì§€ë§‰)
            st.markdown("**â‘¤ í•´ì‹œíƒœê·¸ (ë§ˆì§€ë§‰)**")
            tags = " ".join(data.get("hashtags", []))
            copy_block("í•´ì‹œíƒœê·¸ ë³µì‚¬", tags, 80)

        except Exception as e:
            st.error(f"ìœ íŠœë¸Œ ìƒì„± ì˜¤ë¥˜: {e}")

# =============================
# ë¸”ë¡œê·¸ ìƒì„± (â‰¥1500ì)
# =============================
with colB:
    st.markdown("### âœï¸ ë¸”ë¡œê·¸ íŒ¨í‚¤ì§€ â€” ì œëª©â†’ë³¸ë¬¸(â‰¥1500ì)â†’ì´ë¯¸ì§€â†’íƒœê·¸")
    if st.button("â–¶ ë¸”ë¡œê·¸ ìƒì„±", type="primary"):
        try:
            sys = (
                "You are a Korean Naver-SEO writer. Always return STRICT JSON only (no prose). "
                "Body must be >= 1500 Korean characters with short paragraphs and lists."
            )
            user = f"""
[ì£¼ì œ] {topic}
[íƒ€ê¹ƒ] {audience}
[í†¤] {tone}

Return JSON with this schema:
{{
  "titles": ["...", "...", "..."],
  "body": "(>=1500ì í•œêµ­ì–´ ë³¸ë¬¸)",
  "image_prompts": [
     {{"label":"ëŒ€í‘œ","en":"...","ko":"..."}},
     {{"label":"ë³¸ë¬¸1","en":"...","ko":"..."}},
     {{"label":"ë³¸ë¬¸2","en":"...","ko":"..."}}
  ],
  "hashtags": ["#..", "#..", "#..", "#.."]
}}
- Constraints: titles first; hashtags last; no phone CTA for info posts; friendly senior tone; include [ì´ë¯¸ì§€: ...] markers 2~3 places.
"""
            raw = chat_complete(sys, user, model_text, temperature)
            try:
                data = json.loads(raw)
            except Exception:
                sys2 = sys + " Return ONLY compact JSON without prose."
                raw = chat_complete(sys2, user, model_text, temperature)
                data = json.loads(raw)

            body = data.get("body", "")
            # ê¸¸ì´ ë³´ì • ë£¨í”„(ìµœì†Œ 1500ì)
            if len(body) < 1500:
                sys_len = "Expand to >= 1700 Korean characters while keeping structure and headings. Return JSON only with same fields."
                raw2 = chat_complete(sys_len, json.dumps(data, ensure_ascii=False), model_text, 0.5)
                try:
                    data2 = json.loads(raw2)
                    body = data2.get("body", body)
                    data = data2
                except Exception:
                    pass

            # ì—…ìŠ¤ì¼€ì¼(ì„ íƒ) â€” ë¬¸ì¥ ë‹¤ë“¬ê¸°
            if polish_toggle:
                sys_p = "Polish Korean writing for clarity and flow. Keep JSON structure."
                polished = chat_complete(sys_p, json.dumps(data, ensure_ascii=False), "gpt-4o", 0.4)
                try:
                    data = json.loads(polished)
                    body = data.get("body", body)
                except Exception:
                    pass

            # â‘  ì œëª©
            st.markdown("**â‘  ë¸”ë¡œê·¸ ì œëª© 3ê°œ**")
            blog_titles = [f"{i+1}. {t}" for i, t in enumerate(data.get("titles", [])[:3])]
            copy_block("ë¸”ë¡œê·¸ ì œëª© ë³µì‚¬", "\n".join(blog_titles), 110)

            # â‘¡ ë³¸ë¬¸
            st.markdown("**â‘¡ ë³¸ë¬¸ (â‰¥1500ì)**")
            copy_block("ë¸”ë¡œê·¸ ë³¸ë¬¸ ë³µì‚¬", body, 360)

            # â‘¢ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸
            st.markdown("**â‘¢ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (EN + KO)**")
            for p in data.get("image_prompts", []):
                lbl = p.get("label", "ì´ë¯¸ì§€")
                copy_block(f"[{lbl}] EN", p.get("en", ""), 100)
                copy_block(f"[{lbl}] KO", p.get("ko", ""), 90)

            # â‘£ í•´ì‹œíƒœê·¸ (ë§ˆì§€ë§‰)
            st.markdown("**â‘£ í•´ì‹œíƒœê·¸ (ë§ˆì§€ë§‰)**")
            tags = "\n".join(data.get("hashtags", []))
            copy_block("ë¸”ë¡œê·¸ íƒœê·¸ ë³µì‚¬", tags, 100)

        except Exception as e:
            st.error(f"ë¸”ë¡œê·¸ ìƒì„± ì˜¤ë¥˜: {e}")

st.markdown("---")
st.caption("â€» ê³ í’ˆì§ˆ ëª¨ë“œê°€ í•„ìš”í•˜ë©´ ì‚¬ì´ë“œë°”ì˜ 'í’ˆì§ˆ ì—…ìŠ¤ì¼€ì¼(4oë¡œ í›„ê°€ê³µ)'ì„ ì¼œì„¸ìš”. í˜¸ì¶œëŸ‰ì´ ëŠ˜ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
