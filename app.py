# -*- coding: utf-8 -*-
# ë¸”ë¡œê·¸Â·ìœ íŠœë¸Œ í†µí•© ìƒì„±ê¸° â€” ìµœì¢… ì•ˆì •í™”ë³¸ (ì„¸ì…˜ì˜¤ë¥˜/ë¬´í•œë¡œë”© íŒ¨ì¹˜ ì™„ë£Œ)

import os, re, json, time, uuid, inspect, html
from datetime import datetime, timezone, timedelta
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FuturesTimeout
import streamlit as st
from streamlit.components.v1 import html as comp_html
from openai import OpenAI

# ========================= ê¸°ë³¸ ì„¤ì • =========================
KST = timezone(timedelta(hours=9))
SAFE_BOOT    = True
CTA          = "ê°•ìŒ¤ì² ë¬¼ ì§‘ìˆ˜ë¦¬ ê´€ì•…ì ì— ì§€ê¸ˆ ë°”ë¡œ ë¬¸ì˜ì£¼ì„¸ìš”. ìƒë‹´ë¬¸ì˜: 010-2276-8163"

st.set_page_config(page_title="ë¸”ë¡œê·¸Â·ìœ íŠœë¸Œ í†µí•© ìƒì„±ê¸°", page_icon="âš¡", layout="wide")
st.title("âš¡ ë¸”ë¡œê·¸Â·ìœ íŠœë¸Œ í†µí•© ìƒì„±ê¸° (ìµœì¢… ì•ˆì •í™”ë³¸)")
st.caption(f"KST {datetime.now(KST).strftime('%Y-%m-%d %H:%M')} Â· í•œêµ­ì–´ ê³ ì • Â· EN ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ Â· ë¬´í•œë¡œë”© ë°©ì§€")

# ì„¸ì…˜ ê¸°ë³¸ê°’(ì½ê¸° ì•ˆì „ ìœ„í•´ ê¸°ë³¸ê°’ì„ ê¼­ ì„¸íŒ…)
st.session_state.setdefault("model_text", "gpt-4o-mini")
st.session_state.setdefault("_humanize_calls", 0)
st.session_state.setdefault("_humanize_used",  0.0)
st.session_state.setdefault("people_taste", True)

HUMANIZE_BUDGET_CALLS = 8
HUMANIZE_BUDGET_SECS  = 20.0

# components.html key ì§€ì› í™•ì¸
try:
    HTML_SUPPORTS_KEY = 'key' in inspect.signature(comp_html).parameters
except Exception:
    HTML_SUPPORTS_KEY = False

# ========================= API í‚¤ ìë™ ì ê²€ =========================
def _load_api_key():
    return os.getenv("OPENAI_API_KEY", st.secrets.get("OPENAI_API_KEY", ""))

def _check_api_health():
    api_key = _load_api_key()
    if not api_key:
        st.error("âŒ OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. Streamlit Secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì— ë“±ë¡í•´ ì£¼ì„¸ìš”.")
        st.stop()
    try:
        client = OpenAI(api_key=api_key, timeout=30)
        _ = client.models.list()   # í—¬ìŠ¤ì²´í¬
        st.success("âœ… OpenAI API ì—°ê²° ì„±ê³µ")
        return client
    except Exception as e:
        st.error("âš ï¸ OpenAI API ì—°ê²° ì‹¤íŒ¨ (í‚¤/í”„ë¡œì íŠ¸ ê¶Œí•œ/ë„¤íŠ¸ì›Œí¬ í™•ì¸)")
        st.exception(e)
        st.stop()

_ = _check_api_health()

# ========================= ë³µì‚¬ ë¸”ë¡ =========================
def _copy_iframe_html(title: str, esc_text: str, height: int) -> str:
    return f"""
<!DOCTYPE html><html><head><meta charset="utf-8" />
<style>
body{{margin:0;font-family:system-ui,-apple-system,'Noto Sans KR',Arial}}
.wrap{{border:1px solid #e5e7eb;border-radius:10px;padding:10px}}
.ttl{{font-weight:600;margin-bottom:6px}}
textarea{{width:100%;height:{height}px;border:1px solid #d1d5db;border-radius:8px;padding:8px;
         white-space:pre-wrap;box-sizing:border-box;font-family:ui-monospace,Menlo,Consolas}}
.row{{display:flex;gap:8px;align-items:center;margin-top:8px}}
.btn{{padding:6px 10px;border-radius:8px;border:1px solid #d1d5db;cursor:pointer;background:#fff}}
small{{color:#6b7280}}
</style></head><body>
<div class="wrap">
  <div class="ttl">{html.escape(title or '')}</div>
  <textarea id="ta" readonly>{esc_text}</textarea>
  <div class="row">
    <button class="btn" id="copyBtn">ğŸ“‹ ë³µì‚¬</button>
    <small>ì•ˆ ë˜ë©´ í…ìŠ¤íŠ¸ í´ë¦­ â†’ Ctrl+A â†’ Ctrl+C</small>
  </div>
</div>
<script>
(()=>{{const b=document.getElementById("copyBtn");const t=document.getElementById("ta");
if(!b||!t)return;b.onclick=async()=>{{try{{await navigator.clipboard.writeText(t.value);
b.textContent="âœ… ë³µì‚¬ë¨";setTimeout(()=>b.textContent="ğŸ“‹ ë³µì‚¬",1200)}}catch(e){{try{{t.focus();t.select();document.execCommand("copy");
b.textContent="âœ… ë³µì‚¬ë¨";setTimeout(()=>b.textContent="ğŸ“‹ ë³µì‚¬",1200)}}catch(err){{alert("ë³µì‚¬ê°€ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì§ì ‘ ì„ íƒí•´ ë³µì‚¬í•´ì£¼ì„¸ìš”.")}}}}}})();
</script></body></html>
"""

def copy_block(title: str, text: str, height: int = 160, use_button: bool = True):
    if use_button:
        esc_t = (text or "").replace("&","&amp;").replace("<","&lt;").replace(">","&gt;")
        html_str = _copy_iframe_html(title or "", esc_t, height)
        try:
            if HTML_SUPPORTS_KEY:
                comp_html(html_str, height=height+110, scrolling=False, key=f"copy_{uuid.uuid4().hex}")
            else:
                comp_html(html_str, height=height+110, scrolling=False)
        except TypeError:
            comp_html(html_str, height=height+110)
    else:
        st.markdown(f"**{title or ''}**")
        st.text_area("", text or "", height=height, key=f"ta_{uuid.uuid4().hex}")
        st.caption("ë³µì‚¬: ì˜ì—­ í´ë¦­ â†’ Ctrl+A â†’ Ctrl+C")

# ========================= OpenAI/LLM í—¬í¼ =========================
def _client():
    ak = _load_api_key()
    if not ak:
        st.warning("ğŸ” OPENAI_API_KEY ì—†ìŒ", icon="âš ï¸"); st.stop()
    return OpenAI(api_key=ak, timeout=60)

def _extract_from_responses(r):
    txt = getattr(r, "output_text", None)
    if isinstance(txt, str) and txt.strip():
        return txt.strip()
    parts = []
    for item in getattr(r, "output", []) or []:
        for ct in getattr(item, "content", []) or []:
            if getattr(ct, "type", "") in ("output_text", "text"):
                t = getattr(ct, "text", "") or ""
                if t: parts.append(t)
    return "\n".join(parts).strip()

@st.cache_data(show_spinner=False)
def chat_cached(system, user, model, temperature):
    """ë¬´í•œëŒ€ê¸° ì°¨ë‹¨: 40ì´ˆ í•˜ë“œ íƒ€ì„ì•„ì›ƒ + responses í´ë°±"""
    REQUEST_DEADLINE = 40
    c = _client()

    def call_chat():
        return c.chat.completions.create(
            model=model,
            temperature=temperature,
            max_tokens=2200,
            messages=[{"role":"system","content":system},{"role":"user","content":user}],
        ).choices[0].message.content.strip()

    def call_responses_fallback():
        r = c.responses.create(
            model=model,
            input=[{"role":"system","content":system},{"role":"user","content":user}],
            max_output_tokens=2200,
            temperature=temperature,
        )
        return _extract_from_responses(r)

    def guarded_call():
        try: return call_chat()
        except Exception: return call_responses_fallback()

    waits = [0.0, 0.8]  # 2íšŒ ì‹œë„
    start = time.time()
    for w in waits:
        if w: time.sleep(w)
        remain = REQUEST_DEADLINE - (time.time() - start)
        if remain <= 0: break
        try:
            with ThreadPoolExecutor(max_workers=1) as ex:
                fut = ex.submit(guarded_call)
                return fut.result(timeout=max(5, remain))
        except (FuturesTimeout, Exception):
            continue

    # ì™„ì „ ì‹¤íŒ¨ ì‹œ ì•ˆì „ JSON ë°˜í™˜(ë Œë” ê°•ì œ)
    return json.dumps({
        "youtube": {
            "titles": [f"ì„ì‹œ ì œëª© {i}" for i in range(1,11)],
            "description": "ë„¤íŠ¸ì›Œí¬ ì§€ì—°ìœ¼ë¡œ ì„ì‹œ ì„¤ëª…ì…ë‹ˆë‹¤.",
            "chapters": [{"title":"ì„ì‹œ ì±•í„°","script":"ì„ì‹œ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤."}],
            "images":{"thumbnail":{"en":"Korean context thumbnail, no text overlay"},
                      "chapters":[{"index":1,"en":"support visual, no text overlay"}]},
            "hashtags":["#ì„ì‹œ","#ìƒì„±","#ë³´ë¥˜"]*7
        },
        "blog": {
            "titles": [f"ì„ì‹œ ë¸”ë¡œê·¸ ì œëª© {i}" for i in range(1,11)],
            "body": "ë„¤íŠ¸ì›Œí¬ ì§€ì—°ìœ¼ë¡œ ì„ì‹œ ë³¸ë¬¸ì…ë‹ˆë‹¤.\n\n[ì´ë¯¸ì§€:ëŒ€í‘œ]",
            "images":[{"label":"ëŒ€í‘œ","en":"Korean context, no text overlay"}],
            "tags":["#ì„ì‹œ","#ë¸”ë¡œê·¸","#íƒœê·¸"]*7
        }
    }, ensure_ascii=False)

def run_step_with_deadline(fn, deadline_sec=75, *a, **kw):
    with ThreadPoolExecutor(max_workers=1) as _ex:
        fut = _ex.submit(fn, *a, **kw)
        try:
            return fut.result(timeout=deadline_sec)
        except FuturesTimeout:
            raise TimeoutError(f"Step exceeded {deadline_sec}s")

# ========================= ìœ í‹¸/ë³´ì • =========================
def safe_json_parse(raw, fallback):
    try: return json.loads(raw) if raw else fallback
    except Exception: return fallback

def _is_mostly_english(text: str) -> bool:
    if not text: return False
    letters = sum(ch.isalpha() for ch in text)
    if letters == 0: return False
    ascii_letters = sum(('a' <= ch.lower() <= 'z') for ch in text)
    return (ascii_letters / max(letters,1)) > 0.4

def ensure_korean_lines(lines, model):
    if not lines: return lines
    sample = " ".join(lines[:3])
    if _is_mostly_english(sample):
        ko = chat_cached("ì•„ë˜ ëª©ë¡ì„ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­. ì¤„ ìˆ˜/ìˆœì„œ ìœ ì§€, ê³¼ì¥ ê¸ˆì§€.",
                         "\n".join(lines), model, 0.2)
        out = [ln.strip() for ln in ko.splitlines() if ln.strip()]
        return out[:len(lines)]
    return lines

def humanize_ko(text: str, mode: str, model: str, region: str = "ê´€ì•…êµ¬", persona: str = "ê°•ìŒ¤") -> str:
    """ì„¸ì…˜ ì•ˆì „ ì ‘ê·¼(.get) + ì˜ˆì™¸ ì—†ëŠ” ì—…ë°ì´íŠ¸"""
    if not text:
        return text

    # ì•ˆì „ ì½ê¸° (ìŠ¤ë ˆë“œì—ì„œë„ KeyError ë°©ì§€)
    calls = st.session_state.get("_humanize_calls", 0)
    used  = st.session_state.get("_humanize_used", 0.0)

    start_ts = time.time()
    if (calls >= HUMANIZE_BUDGET_CALLS) or (used >= HUMANIZE_BUDGET_SECS):
        return text

    style_sys = (
        "ë‹¹ì‹ ì€ í•œêµ­ì–´ ê¸€ë§›ì„ ì‚´ë¦¬ëŠ” í¸ì§‘ìì…ë‹ˆë‹¤. ê³¼ì¥/ê´‘ê³ í†¤ ì–µì œ, 2~3ë¬¸ì¥ë§ˆë‹¤ í˜¸í¡, "
        f"ì§€ì—­({region})ê³¼ í˜„ì¥ì „ë¬¸ê°€ '{persona}'ì˜ ë§íˆ¬ë¥¼ ì•½í•˜ê²Œ ìŠ¤ë©°ë“¤ê²Œ."
    )
    mode_line = "ì˜ì—…í˜•: CTAëŠ” ë§ˆì§€ë§‰ 1ì¤„ë§Œ." if mode == "sales" else "ì •ë³´í˜•: CTA ê¸ˆì§€."
    ask = f"{mode_line}\n\n[ì›ë¬¸]\n{text}\n\nì›ë¬¸ êµ¬ì¡°ëŠ” ìœ ì§€, ë¦¬ë“¬ê³¼ ì–´íœ˜ë§Œ ê°œì„ ."

    out = chat_cached(style_sys, ask, model, 0.6)

    # ì•ˆì „ ì—…ë°ì´íŠ¸
    try:
        st.session_state["_humanize_calls"] = calls + 1
        st.session_state["_humanize_used"]  = used + (time.time() - start_ts)
    except Exception:
        pass

    return out

# ========================= íƒ€ê¹ƒ/ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ =========================
def detect_demo_from_topic(topic: str):
    t = (topic or "").lower()
    age = "ì„±ì¸"
    age_map = [
        (r"(ìœ ì•„|ì˜ìœ ì•„|ì‹ ìƒì•„)", "ìœ ì•„"),
        (r"(ì•„ë™|ì´ˆë“±|ì´ˆë“±í•™ìƒ|í‚¤ì¦ˆ)", "ì•„ë™"),
        (r"(ì²­ì†Œë…„|ì¤‘í•™ìƒ|ê³ ë“±í•™ìƒ|10ëŒ€|í‹´|í‹°ë„¤ì´ì €)", "ì²­ì†Œë…„"),
        (r"(20ëŒ€|2030)", "20ëŒ€"),
        (r"(30ëŒ€|3040)", "30ëŒ€"),
        (r"(40ëŒ€|4050)", "40ëŒ€"),
        (r"(50ëŒ€|ì¥ë…„|ì¤‘ë…„)", "50ëŒ€"),
        (r"(60ëŒ€|ë…¸ë…„|ì‹œë‹ˆì–´)", "60ëŒ€"),
        (r"(70ëŒ€|ê³ ë ¹)", "70ëŒ€"),
    ]
    for pat,label in age_map:
        if re.search(pat, t): age = label; break
    if re.search(r"(ë‚¨ì„±|ë‚¨ì|ì•„ë¹ |í˜•|ì‚¼ì´Œ|ì‹ ì‚¬|ë‚¨í¸|ì¤‘ë…„ë‚¨|ì•„ì¬)", t): gender = "ë‚¨ì„±"
    elif re.search(r"(ì—¬ì„±|ì—¬ì|ì—„ë§ˆ|ì–¸ë‹ˆ|ì´ëª¨|ìˆ™ë…€|ì•„ë‚´|ì¤‘ë…„ì—¬|ì—¬ì„±ì „ìš©)", t): gender = "ì—¬ì„±"
    else: gender = "í˜¼í•©"
    return age, gender

def build_kr_image_en(subject_en: str, age: str, gender: str, place: str, mood: str, shot: str, style: str) -> str:
    age_en = {"ìœ ì•„":"toddlers","ì•„ë™":"children","ì²­ì†Œë…„":"teenagers","20ëŒ€":"people in their 20s",
              "30ëŒ€":"people in their 30s","40ëŒ€":"people in their 40s","50ëŒ€":"people in their 50s",
              "60ëŒ€":"people in their 60s","70ëŒ€":"people in their 70s","ì„±ì¸":"adults"}.get(age,"adults")
    gender_en = {"ë‚¨ì„±":"Korean man","ì—¬ì„±":"Korean woman","í˜¼í•©":"Korean men and women"}.get(gender,"Korean men and women")
    place_en = {
        "í•œêµ­ ê°€ì • ê±°ì‹¤":"modern Korean home living room interior",
        "í•œêµ­ ì•„íŒŒíŠ¸ ë‹¨ì§€":"Korean apartment complex outdoor area",
        "í•œêµ­ ë™ë„¤ ê³µì›":"local Korean neighborhood park",
        "í•œêµ­ ë³‘ì›/ê²€ì§„ì„¼í„°":"Korean medical clinic or health screening center interior",
        "í•œêµ­í˜• ì£¼ë°©/ì‹íƒ":"modern Korean kitchen and dining table"
    }.get(place,"modern Korean interior")
    shot_en  = {"í´ë¡œì¦ˆì—…":"close-up","ìƒë°˜ì‹ ":"medium shot","ì „ì‹ ":"full body shot","íƒ‘ë·°/í…Œì´ë¸”ìƒ·":"top view table shot"}.get(shot,"medium shot")
    mood_en  = {"ë”°ëœ»í•œ":"warm","ë°ì€":"bright","ì°¨ë¶„í•œ":"calm","í™œê¸°ì°¬":"energetic"}.get(mood,"warm")
    style_en = {"ì‚¬ì§„ ì‹¤ì‚¬":"realistic photography, high resolution","ì‹œë„¤ë§ˆí‹±":"cinematic photo style",
                "ì¡ì§€ í™”ë³´":"editorial magazine style","ìì—°ê´‘":"natural lighting"}.get(style,"realistic photography, high resolution")
    return (f"{gender_en} {age_en} at a {place_en}, {shot_en}, {mood_en} mood, {style_en}. "
            f"Context: {subject_en}. natural lighting, high contrast, no text overlay, no captions, no watermarks, no logos.")

# ========================= ì‚¬ì´ë“œë°” =========================
with st.sidebar:
    st.header("âš™ï¸ ìƒì„± ì„¤ì •")
    st.selectbox("ëª¨ë¸", ["gpt-4o-mini","gpt-4o"], index=0, key="model_text")
    temperature  = st.slider("ì°½ì˜ì„±", 0.0, 1.2, 0.6, 0.1)

    st.markdown("---")
    safe_mode = st.checkbox("ì•ˆì • ëª¨ë“œ(ë‹¨ì¼ ìš”ì²­)", value=True)
    include_thumb  = st.checkbox("ì¸ë„¤ì¼ í”„ë¡¬í”„íŠ¸ í¬í•¨", value=True)
    target_chapter = st.selectbox("ìœ íŠœë¸Œ ìë§‰ ê°œìˆ˜", [5,6,7], 0)

    st.markdown("---")
    st.markdown("### ğŸ–¼ í•œêµ­ì¸ ê³ ì • + ìë™ ì—°ë ¹/ì„±ë³„")
    img_age    = st.selectbox("ì—°ë ¹", ["ìë™","ìœ ì•„","ì•„ë™","ì²­ì†Œë…„","20ëŒ€","30ëŒ€","40ëŒ€","50ëŒ€","60ëŒ€","70ëŒ€","ì„±ì¸"], 0)
    img_gender = st.selectbox("ì„±ë³„", ["ìë™","í˜¼í•©","ë‚¨ì„±","ì—¬ì„±"], 0)
    img_place  = st.selectbox("ì¥ì†Œ", ["í•œêµ­ ê°€ì • ê±°ì‹¤","í•œêµ­ ì•„íŒŒíŠ¸ ë‹¨ì§€","í•œêµ­ ë™ë„¤ ê³µì›","í•œêµ­ ë³‘ì›/ê²€ì§„ì„¼í„°","í•œêµ­í˜• ì£¼ë°©/ì‹íƒ"], 0)
    img_mood   = st.selectbox("ë¬´ë“œ", ["ë”°ëœ»í•œ","ë°ì€","ì°¨ë¶„í•œ","í™œê¸°ì°¬"], 0)
    img_shot   = st.selectbox("ìƒ·", ["í´ë¡œì¦ˆì—…","ìƒë°˜ì‹ ","ì „ì‹ ","íƒ‘ë·°/í…Œì´ë¸”ìƒ·"], 1)
    img_style  = st.selectbox("ìŠ¤íƒ€ì¼", ["ì‚¬ì§„ ì‹¤ì‚¬","ì‹œë„¤ë§ˆí‹±","ì¡ì§€ í™”ë³´","ìì—°ê´‘"], 0)

    st.markdown("---")
    st.markdown("### ğŸ“ ë¸”ë¡œê·¸ ê°•í™”")
    blog_min   = st.slider("ìµœì†Œ ê¸¸ì´(ì)", 1500, 4000, 2200, 100)
    blog_imgs  = st.selectbox("ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìˆ˜", [3,4,5,6], 2)
    tag_join_style = st.radio("ë¸”ë¡œê·¸ íƒœê·¸ ê²°í•© ë°©ì‹", ["ë„ì–´ì“°ê¸° í•œ ì¤„", "ì¤„ë°”ê¿ˆ ì—¬ëŸ¬ ì¤„"], index=0)

    st.markdown("---")
    people_taste = st.checkbox("ì‚¬ëŒë§› ê°•í™”(2ì°¨ ë‹¤ë“¬ê¸°)", value=st.session_state.get("people_taste", True))
    show_chapter_blocks = st.checkbox("ìë§‰ ê°œë³„ ë³µì‚¬ ë¸”ë¡ í‘œì‹œ", value=False)
    show_img_blocks     = st.checkbox("ì±•í„°/ë¸”ë¡œê·¸ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ í‘œì‹œ", value=False)

    st.markdown("---")
    if st.checkbox("ê°•ì œ ì¬ìƒì„±(ìºì‹œ ë¬´ì‹œ)", value=False):
        st.cache_data.clear()

# ========================= ì…ë ¥ í¼ =========================
st.subheader("ğŸ¯ ì£¼ì œ ë° ë‚´ìš©")
c1,c2,c3,c4 = st.columns([2,1,1,1])
with c1: topic = st.text_input("ì£¼ì œ", value="50ëŒ€ ì´í›„ ì¡°ì‹¬í•´ì•¼ í•  ìŒì‹ TOP5")
with c2: tone  = st.selectbox("í†¤/ìŠ¤íƒ€ì¼", ["ì‹œë‹ˆì–´ ì¹œí™”í˜•","ì „ë¬¸ê°€í˜•","ì¹œê·¼í•œ ì„¤ëª…í˜•"], 1)
with c3: mode_sel = st.selectbox("ì½˜í…ì¸  ìœ í˜•", ["ìë™ ë¶„ë¥˜","ì •ë³´í˜•(ë¸”ë¡œê·¸ ì§€ìˆ˜)","ì‹œê³µí›„ê¸°í˜•(ì˜ì—…)"], 1)
with c4: target = st.selectbox("ìƒì„± ëŒ€ìƒ", ["ìœ íŠœë¸Œ + ë¸”ë¡œê·¸","ìœ íŠœë¸Œë§Œ","ë¸”ë¡œê·¸ë§Œ"], 0)

def classify(txt):
    return "sales" if any(k in txt for k in ["ì‹œê³µ","êµì²´","ì„¤ì¹˜","ìˆ˜ë¦¬","ëˆ„ìˆ˜","ë³´ìˆ˜","í›„ê¸°","í˜„ì¥","ê´€ì•…","ê°•ìŒ¤ì² ë¬¼"]) else "info"
def ensure_mode():
    if mode_sel=="ì •ë³´í˜•(ë¸”ë¡œê·¸ ì§€ìˆ˜)": return "info"
    if mode_sel=="ì‹œê³µí›„ê¸°í˜•(ì˜ì—…)":   return "sales"
    return classify(topic)
mode = ensure_mode()

auto_age, auto_gender = detect_demo_from_topic(topic)
final_age    = auto_age    if img_age    == "ìë™" else img_age
final_gender = auto_gender if img_gender == "ìë™" else img_gender

if SAFE_BOOT: st.caption("ì˜µì…˜ í™•ì¸ í›„ ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ì‹¤í–‰í•˜ì„¸ìš”.")
go = st.button("â–¶ í•œ ë²ˆì— ìƒì„±", type="primary")

# ì“°ë ˆë“œ ë°–ì—ì„œ ëª¨ë¸ê°’ ê³ ì •(ì„¸ì…˜ ì§ì ‘ ì ‘ê·¼ ê¸ˆì§€)
MODEL = st.session_state.get("model_text", "gpt-4o-mini")

# ========================= LLM ìŠ¤í‚¤ë§ˆ =========================
def schema_for_llm(_:int):
    return f'''{{
  "demographics": {{
    "age_group": "{final_age}",
    "gender": "{final_gender}"
  }}
}}'''

# ========================= ìƒì„± í•¨ìˆ˜ =========================
def gen_youtube(topic, tone, n, mode, model):
    sys = (
      "[persona / voice rules]\n"
      "- í™”ì: 20ë…„ ì°¨ í˜„ì¥ ì „ë¬¸ê°€ â€˜ê°•ìŒ¤â€™. ì°¨ë¶„+ê°€ë²¼ìš´ ìœ ë¨¸. ì¡´ëŒ€.\n"
      "- ë¦¬ë“¬: ì§§/ê¸´ ë¬¸ì¥ ì„ê³  2~3ë¬¸ì¥ë§ˆë‹¤ í˜¸í¡.\n"
      "- ì‚¬ë¡€ 1ê°œ ì´ìƒ, ë¹„êµ/ì£¼ì˜/ëŒ€ì•ˆ í¬í•¨. ë§ˆë¬´ë¦¬ 2ì¤„ ìš”ì•½+ì²´í¬ 3~5.\n\n"
      "You are a seasoned Korean YouTube scriptwriter. Return STRICT JSON ONLY.\n"
      "IMPORTANT: 'titles', 'description', and 'chapters' MUST be written in KOREAN.\n"
      "Image prompts MUST be in ENGLISH ONLY and include 'no text overlay'.\n"
      "SEO titles (10, Korean) should include the main keyword early and avoid clickbait.\n"
      "Provide exactly N chapters (3~5 sentences each). All visuals in Korean context."
    )
    user = (f"[topic] {topic}\n[tone] {tone}\n[mode] {'info' if mode=='info' else 'sales'}\n[N] {n}\n"
            f"[demographics] age={final_age}, gender={final_gender}\n[schema]\n{schema_for_llm(0)}")
    raw = chat_cached(sys, user, model, temperature)
    data = safe_json_parse(raw, {})
    yt = data.get("youtube") or {
        "titles":[f"{topic} í•µì‹¬ ê°€ì´ë“œ {i+1}" for i in range(10)],
        "description": f"{topic} ìš”ì•½ ê°€ì´ë“œì…ë‹ˆë‹¤.",
        "chapters":[{"title":f"Tip{i+1}","script":f"{topic} í•µì‹¬ í¬ì¸íŠ¸ {i+1}"} for i in range(n)],
        "images":{"thumbnail":{"en":"Korean home thumbnail, no text overlay"},
                  "chapters":[{"index":i+1,"en":"support visual, no text overlay"} for i in range(n)]},
        "hashtags":["#ê±´ê°•","#ê´€ë¦¬","#ìƒí™œ"]*5
    }

    yt["titles"] = ensure_korean_lines(yt.get("titles", [])[:10], model)
    desc = yt.get("description","")
    if _is_mostly_english(desc):
        yt["description"] = chat_cached("ì´ ì„¤ëª…ì„ í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë°”ê¾¸ì„¸ìš”. ê³¼ì¥ ì—†ì´ ê°„ê²°í•˜ê²Œ.", desc, model, 0.2)

    chs = []
    for c in yt.get("chapters", [])[:n]:
        sc = c.get("script","")
        if _is_mostly_english(sc):
            sc = chat_cached("ì•„ë˜ ë¬¸ë‹¨ì„ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë°”ê¾¸ì„¸ìš”.", sc, model, 0.2)
        chs.append({"title": c.get("title",""), "script": sc})
    yt["chapters"] = chs

    if mode=="sales":
        desc = (yt.get("description","") or "").rstrip()
        if CTA not in desc: yt["description"] = (desc + f"\n{CTA}").strip()

    if st.session_state.get("people_taste", True):
        yt["description"] = humanize_ko(yt.get("description",""), mode, model)
        for c in yt["chapters"]:
            c["script"] = humanize_ko(c.get("script",""), mode, model)
    return yt

def gen_blog(topic, tone, mode, min_chars, img_count, model):
    sys = (
      "[persona / voice rules]\n"
      "- í™”ì: 20ë…„ ì°¨ í˜„ì¥ ì „ë¬¸ê°€ â€˜ê°•ìŒ¤â€™. ì°¨ë¶„+ê°€ë²¼ìš´ ìœ ë¨¸. ì¡´ëŒ€.\n"
      "- ë¦¬ë“¬: ì§§/ê¸´ ë¬¸ì¥ ì„ê¸°, 2~3ë¬¸ì¥ë§ˆë‹¤ í˜¸í¡. í˜„ì¥ ë””í…Œì¼ 1~2ê°œ.\n"
      "- ì‚¬ë¡€/ë¹„êµ/ì£¼ì˜/ëŒ€ì•ˆ í¬í•¨. ë§ˆë¬´ë¦¬ 2ì¤„ ìš”ì•½+ì²´í¬ 3~5.\n\n"
      "You are a Korean SEO writer for Naver blog. Return STRICT JSON ONLY.\n"
      f"Body MUST be >= {min_chars} Korean characters and include 3~5 '[ì´ë¯¸ì§€:ëŒ€í‘œ/ë³¸ë¬¸1/ë³¸ë¬¸2/ë³¸ë¬¸3/ë³¸ë¬¸4]' markers.\n"
      "Structure: ì„œë¡  â†’ í•µì‹¬5 â†’ ì²´í¬ë¦¬ìŠ¤íŠ¸(6~8) â†’ ìê°€ì§„ë‹¨(5) â†’ FAQ(3) â†’ ë§ˆë¬´ë¦¬.\n"
      "Info mode forbids CTA. Sales mode allows ONE CTA at the very last line.\n"
      "Provide 10 SEO titles, 20 tags, and EN image prompts with NO TEXT OVERLAY."
    )
    user = (f"[topic] {topic}\n[tone] {tone}\n[mode] {'info' if mode=='info' else 'sales'}\n"
            f"[demographics] age={final_age}, gender={final_gender}\n[schema]\n{schema_for_llm(min_chars)}")
    raw = chat_cached(sys, user, model, temperature)
    data = safe_json_parse(raw, {})
    blog = data.get("blog") or {
        "titles":[f"{topic} ë¸”ë¡œê·¸ {i+1}" for i in range(10)],
        "body":f"{topic} ê¸°ë³¸ ì•ˆë‚´",
        "images":[{"label":"ëŒ€í‘œ","en":"Korean home context, no text overlay"}],
        "tags":["#ê±´ê°•","#ì‹ë‹¨","#ìƒí™œ","#ê´€ë¦¬"]*5
    }

    if len(blog.get("body","")) < min_chars:
        def _expand():
            return chat_cached(
                f"Expand to >={min_chars+300} Korean characters; keep structure & markers; RETURN JSON ONLY.",
                json.dumps({"blog":blog}, ensure_ascii=False),
                model, 0.5
            )
        try:
            ext = run_step_with_deadline(_expand, 35)
            blog = safe_json_parse(ext, {"blog":blog}).get("blog", blog)
        except Exception:
            pass

    if mode=="sales":
        if CTA not in blog.get("body",""):
            blog["body"] = blog.get("body","").rstrip() + f"\n\n{CTA}"
    else:
        blog["body"] = blog.get("body","").replace(CTA,"").strip()

    if st.session_state.get("people_taste", True):
        blog["body"] = humanize_ko(blog.get("body",""), mode, model)

    prompts = blog.get("images", [])[:img_count]
    while len(prompts) < img_count:
        i=len(prompts)
        prompts.append({"label":"ëŒ€í‘œ" if i==0 else f"ë³¸ë¬¸{i}",
                        "en":f"support visual for section {i} of '{topic}' (no text overlay)"})
    blog["images"] = prompts
    return blog

# ========================= íƒœê·¸/ë‚´ë³´ë‚´ê¸° =========================
def _join_tags(tags, style: str) -> str:
    return "\n".join(tags) if style == "ì¤„ë°”ê¿ˆ ì—¬ëŸ¬ ì¤„" else " ".join(tags)

def build_blog_body_with_tags(blog: dict, style: str) -> str:
    body = (blog.get("body") or "").rstrip()
    tags = _join_tags(blog.get("tags", []), style)
    return f"{body}\n\n{tags}".strip() if tags else body

def build_youtube_txt(yt: dict) -> str:
    titles = "\n".join(f"{i+1}. {t}" for i,t in enumerate(yt.get('titles',[])[:10]))
    chapters = "\n\n".join(f"[ì±•í„° {i+1}] {c.get('title','')}\n{c.get('script','')}"
                           for i,c in enumerate(yt.get('chapters',[])))
    desc = yt.get('description','').strip()
    tags = " ".join(yt.get('hashtags',[]))
    return f"# YouTube Package\n\n## Titles\n{titles}\n\n## Description\n{desc}\n\n## Chapters\n{chapters}\n\n## Hashtags\n{tags}\n"

def build_blog_md(blog: dict) -> str:
    titles = "\n".join(f"{i+1}. {t}" for i,t in enumerate(blog.get('titles',[])[:10]))
    body = blog.get('body','')
    tags = " ".join(blog.get('tags',[]))
    return f"# Blog Package\n\n## Titles\n{titles}\n\n## Body\n{body}\n\n## Tags\n{tags}\n"

# ========================= ì‹¤í–‰ (ìˆœì°¨ + ì›Œì¹˜ë…) =========================
if go:
    try:
        st.session_state["people_taste"] = people_taste

        do_yt   = target in ["ìœ íŠœë¸Œ + ë¸”ë¡œê·¸","ìœ íŠœë¸Œë§Œ"]
        do_blog = target in ["ìœ íŠœë¸Œ + ë¸”ë¡œê·¸","ë¸”ë¡œê·¸ë§Œ"]

        prog = st.progress(0); prog_text = st.empty()
        status = st.status("ì‹¤í–‰ ë¡œê·¸", expanded=False); status.write("ì´ˆê¸°í™”â€¦")
        results = {}

        # ìœ íŠœë¸Œ
        if do_yt:
            prog.progress(15); prog_text.write("ìœ íŠœë¸Œ íŒ¨í‚¤ì§€ ìƒì„± ì¤‘â€¦")
            status.write("ìœ íŠœë¸Œ í”„ë¡¬í”„íŠ¸ ì „ì†¡â€¦")
            results["yt"] = run_step_with_deadline(gen_youtube, 75, topic, tone, target_chapter, mode, MODEL)
            status.write("ìœ íŠœë¸Œ íŒ¨í‚¤ì§€ ìˆ˜ì‹  ì™„ë£Œ")

        # ë¸”ë¡œê·¸
        if do_blog:
            prog.progress(45 if do_yt else 15); prog_text.write("ë¸”ë¡œê·¸ íŒ¨í‚¤ì§€ ìƒì„± ì¤‘â€¦")
            status.write("ë¸”ë¡œê·¸ í”„ë¡¬í”„íŠ¸ ì „ì†¡â€¦")
            results["blog"] = run_step_with_deadline(gen_blog, 90, topic, tone, mode, blog_min, blog_imgs, MODEL)
            status.write("ë¸”ë¡œê·¸ íŒ¨í‚¤ì§€ ìˆ˜ì‹  ì™„ë£Œ")

        # ë Œë”ë§
        prog.progress(85); prog_text.write("í›„ì²˜ë¦¬ ë° ë Œë”ë§â€¦"); status.write("í›„ì²˜ë¦¬â€¦")

        # ===== ìœ íŠœë¸Œ ì¶œë ¥ =====
        if do_yt:
            st.markdown("## ğŸ“º ìœ íŠœë¸Œ íŒ¨í‚¤ì§€")
            yt = results.get("yt", {})
            st.markdown("**â‘  ì˜ìƒ ì œëª©(SEO 10)**")
            titles=[f"{i+1}. {t}" for i,t in enumerate(yt.get("titles",[])[:10])]
            copy_block("ì˜ìƒ ì œëª© ë³µì‚¬", "\n".join(titles), 160, True)

            st.markdown("**â‘¡ ì˜ìƒ ì„¤ëª…**")
            copy_block("ì˜ìƒ ì„¤ëª… ë³µì‚¬", yt.get("description",""), 160, True)

            chapters = yt.get("chapters", [])[:target_chapter]
            full_vrew_script = "\n".join([c.get("script", "").replace("\n", " ") for c in chapters])
            st.markdown("**â‘¢ ë¸Œë£¨ ìë§‰ â€” ì „ì²´ ì¼ê´„ ë³µì‚¬ (Vrew)**")
            copy_block("ë¸Œë£¨ ìë§‰ â€” ì „ì²´ ì¼ê´„", full_vrew_script, 220, True)

            st.markdown("**â‘£ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (EN only, no text overlay)**")
            if include_thumb:
                copy_block("[ì¸ë„¤ì¼] EN",
                           build_kr_image_en(
                               f"YouTube thumbnail for topic: {topic}. Korean home context, healthy living.",
                               final_age, final_gender, img_place, img_mood, img_shot, img_style),
                           110, True)

            st.markdown("**â‘¤ í•´ì‹œíƒœê·¸(20)**")
            copy_block("í•´ì‹œíƒœê·¸ ë³µì‚¬", " ".join(yt.get("hashtags",[])), 90, True)

            st.download_button("â¬‡ï¸ ìœ íŠœë¸Œ íŒ¨í‚¤ì§€ .txt ì €ì¥",
                               build_youtube_txt(yt).encode("utf-8"),
                               file_name="youtube_package.txt", mime="text/plain",
                               key=f"dl_yt_{uuid.uuid4().hex}")

        # ===== ë¸”ë¡œê·¸ ì¶œë ¥ =====
        if do_blog:
            st.markdown("---"); st.markdown("## ğŸ“ ë¸”ë¡œê·¸ íŒ¨í‚¤ì§€")
            blog = results.get("blog", {})
            st.markdown("**â‘  ë¸”ë¡œê·¸ ì œëª©(SEO 10)**")
            bts=[f"{i+1}. {t}" for i,t in enumerate(blog.get("titles",[])[:10])]
            copy_block("ë¸”ë¡œê·¸ ì œëª© ë³µì‚¬", "\n".join(bts), 160, True)

            st.markdown("**â‘¡ ë³¸ë¬¸ (ê°•í™” Â· ì´ë¯¸ì§€ ì•µì»¤ í¬í•¨)**")
            copy_block("ë¸”ë¡œê·¸ ë³¸ë¬¸ ë³µì‚¬", blog.get("body",""), 420, True)

            st.markdown("**â‘¡-Î² ë³¸ë¬¸ + í•´ì‹œíƒœê·¸ (í•œ ë²ˆì— ë³µì‚¬)**")
            combined_text = build_blog_body_with_tags(blog, tag_join_style)
            copy_block("ë¸”ë¡œê·¸ ë³¸ë¬¸+í•´ì‹œíƒœê·¸", combined_text, 460, True)

            st.markdown("**â‘¢ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (EN only, no text overlay)**")
            if blog.get("images"):
                expb = st.expander("ë¸”ë¡œê·¸ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (í¼ì³ì„œ ë³´ê¸°)", expanded=False)
                with expb:
                    for p in blog.get("images",[]):
                        base = p.get("en","") or f"support visual for section '{p.get('label','')}'"
                        copy_block(f"[{p.get('label','ì´ë¯¸ì§€')}] EN",
                                   build_kr_image_en(base, final_age, final_gender, img_place, img_mood, img_shot, img_style),
                                   110, True)

            st.markdown("**â‘£ íƒœê·¸(20)**")
            copy_block("ë¸”ë¡œê·¸ íƒœê·¸ ë³µì‚¬", _join_tags(blog.get("tags",[]), tag_join_style), 100, True)

            st.download_button("â¬‡ï¸ ë¸”ë¡œê·¸ íŒ¨í‚¤ì§€ .md ì €ì¥",
                               build_blog_md(blog).encode("utf-8"),
                               file_name="blog_package.md", mime="text/markdown",
                               key=f"dl_blog_{uuid.uuid4().hex}")

        prog.progress(100); prog_text.write("ì™„ë£Œ")
        status.update(label="ì™„ë£Œ", state="complete")

    except Exception as e:
        st.error("âš ï¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.exception(e)

st.markdown("---")
st.caption("ë¬´í•œë¡œë”© ë°©ì§€(í•˜ë“œ íƒ€ì„ì•„ì›ƒ/í´ë°±) Â· ì„¸ì…˜ ì ‘ê·¼ ì•ˆì „í™”(.get) Â· ìˆœì°¨ ì‹¤í–‰ Â· ëª¨ë¸ ì¸ì ì „ë‹¬ Â· API í‚¤ ìë™ ì ê²€")
